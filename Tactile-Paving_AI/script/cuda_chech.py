import subprocess
import sys
import os

def run_command(command):
    """Komutu Ã§alÄ±ÅŸtÄ±r ve Ã§Ä±ktÄ±yÄ± dÃ¶ndÃ¼r"""
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=10)
        return result.stdout.strip() if result.returncode == 0 else None
    except Exception as e:
        return None

def check_cuda():
    """CUDA sÃ¼rÃ¼mlerini kontrol et"""
    print("=" * 60)
    print("ğŸ” CUDA VE GPU KONTROL ARACI")
    print("=" * 60)
    
    # 1. nvidia-smi kontrolÃ¼
    print("\nğŸ“Š 1. NVIDIA Driver ve Runtime CUDA:")
    print("-" * 60)
    nvidia_smi = run_command("nvidia-smi --query-gpu=driver_version,name,memory.total --format=csv,noheader")
    if nvidia_smi:
        print(f"   âœ… nvidia-smi Ã§alÄ±ÅŸÄ±yor")
        lines = nvidia_smi.split('\n')
        for line in lines:
            print(f"   {line}")
        
        # CUDA version from nvidia-smi
        cuda_version = run_command("nvidia-smi | grep 'CUDA Version' | awk '{print $9}'")
        if cuda_version:
            print(f"   ğŸ¯ Runtime CUDA Version: {cuda_version}")
    else:
        print("   âŒ nvidia-smi bulunamadÄ± veya Ã§alÄ±ÅŸmÄ±yor")
    
    # 2. nvcc kontrolÃ¼ (Compiler CUDA)
    print("\nğŸ”§ 2. CUDA Compiler (nvcc):")
    print("-" * 60)
    nvcc_version = run_command("nvcc --version | grep 'release' | awk '{print $5}' | cut -c2-")
    if nvcc_version:
        print(f"   âœ… nvcc bulundu")
        print(f"   ğŸ¯ Compiler CUDA Version: {nvcc_version}")
    else:
        print("   âŒ nvcc bulunamadÄ± (CUDA Toolkit yÃ¼klÃ¼ deÄŸil olabilir)")
    
    # 3. CUDA path kontrolÃ¼
    print("\nğŸ“ 3. CUDA Yol Kontrolleri:")
    print("-" * 60)
    cuda_home = os.environ.get('CUDA_HOME') or os.environ.get('CUDA_PATH')
    if cuda_home:
        print(f"   âœ… CUDA_HOME: {cuda_home}")
    else:
        print("   âš ï¸  CUDA_HOME environment variable tanÄ±mlÄ± deÄŸil")
    
    # Standart CUDA yollarÄ±nÄ± kontrol et
    cuda_paths = [
        '/usr/local/cuda',
        '/usr/local/cuda-12.8',
        '/usr/local/cuda-12.4',
        '/usr/local/cuda-12.1',
        '/usr/local/cuda-11.8',
        '/usr/local/cuda-11.7',
    ]
    
    found_paths = []
    for path in cuda_paths:
        if os.path.exists(path):
            found_paths.append(path)
    
    if found_paths:
        print(f"   âœ… Bulunan CUDA yollarÄ±:")
        for path in found_paths:
            print(f"      - {path}")
    else:
        print("   âš ï¸  Standart CUDA yollarÄ±nda CUDA bulunamadÄ±")
    
    # 4. PyTorch CUDA kontrolÃ¼
    print("\nğŸ 4. PyTorch CUDA Durumu:")
    print("-" * 60)
    try:
        import torch
        print(f"   âœ… PyTorch Version: {torch.__version__}")
        print(f"   ğŸ¯ CUDA Available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"   âœ… CUDA Version (PyTorch): {torch.version.cuda}")
            print(f"   âœ… cuDNN Version: {torch.backends.cudnn.version()}")
            print(f"   âœ… GPU Count: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                print(f"\n   ğŸ“± GPU {i}:")
                print(f"      - Name: {torch.cuda.get_device_name(i)}")
                props = torch.cuda.get_device_properties(i)
                print(f"      - Memory: {props.total_memory / 1024**3:.2f} GB")
                print(f"      - Compute Capability: {props.major}.{props.minor}")
        else:
            print("   âŒ PyTorch CUDA kullanÄ±lamÄ±yor!")
            print("\n   ğŸ’¡ OlasÄ± sebepler:")
            print("      1. PyTorch CPU versiyonu yÃ¼klÃ¼")
            print("      2. CUDA sÃ¼rÃ¼mÃ¼ PyTorch ile uyumsuz")
            print("      3. NVIDIA driver sorunu")
            
    except ImportError:
        print("   âŒ PyTorch yÃ¼klÃ¼ deÄŸil")
    
    # 5. LD_LIBRARY_PATH kontrolÃ¼
    print("\nğŸ“š 5. Library Path:")
    print("-" * 60)
    ld_path = os.environ.get('LD_LIBRARY_PATH')
    if ld_path:
        cuda_in_path = any('cuda' in p.lower() for p in ld_path.split(':'))
        if cuda_in_path:
            print(f"   âœ… LD_LIBRARY_PATH'te CUDA var")
        else:
            print(f"   âš ï¸  LD_LIBRARY_PATH'te CUDA yok")
    else:
        print("   âš ï¸  LD_LIBRARY_PATH tanÄ±mlÄ± deÄŸil")
    
    # 6. Ã–zet ve Ã–neriler
    print("\n" + "=" * 60)
    print("ğŸ“‹ Ã–ZET VE Ã–NERÄ°LER")
    print("=" * 60)
    
    if nvidia_smi and nvcc_version:
        print("âœ… CUDA donanÄ±m ve yazÄ±lÄ±m desteÄŸi mevcut")
        print(f"âœ… Runtime CUDA: {cuda_version if cuda_version else 'Tespit edilemedi'}")
        print(f"âœ… Compiler CUDA: {nvcc_version}")
    elif nvidia_smi:
        print("âš ï¸  NVIDIA GPU var ama CUDA Toolkit eksik olabilir")
        print("ğŸ’¡ CUDA Toolkit yÃ¼kleyin: https://developer.nvidia.com/cuda-downloads")
    else:
        print("âŒ NVIDIA GPU veya driver tespit edilemedi")
    
    try:
        import torch
        if not torch.cuda.is_available():
            print("\nâŒ PyTorch CUDA kullanamÄ±yor!")
            print("\nğŸ”§ Ã‡Ã–ZÃœMLERÄ°:")
            if cuda_version:
                major_version = cuda_version.split('.')[0]
                print(f"\n   1. PyTorch'u CUDA {cuda_version} iÃ§in yÃ¼kleyin:")
                if major_version in ['12']:
                    print(f"      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
                elif major_version in ['11']:
                    print(f"      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
            else:
                print("\n   1. PyTorch'u CUDA destekli yÃ¼kleyin:")
                print("      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
            
            print("\n   2. Veya conda ile:")
            print("      conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia")
    except:
        pass
    
    print("\n" + "=" * 60)

if __name__ == "__main__":
    check_cuda()